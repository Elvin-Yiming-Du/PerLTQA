# PerLTQA
PerLTQA is a new benchmark for memory classification, retrieval, and synthesis of Large Language Models.

## License

This dataset is licensed under the [CC BY-NC 4.0 License](https://creativecommons.org/licenses/by-nc/4.0/).  
It is intended for non-commercial research use only.

If you use this dataset, please cite the following work:

**PerLTQA: A Personal Long-Term Memory Dataset for Memory Classification, Retrieval, and Fusion in Question Answering**  
Yiming Du, Hongru Wang, Zhengyi Zhao, Bin Liang, Baojun Wang, Wanjun Zhong, Zezhong Wang, and Kam-Fai Wong.  
*Proceedings of the 10th SIGHAN Workshop on Chinese Language Processing (SIGHAN-10)*, 2024.  
[https://aclanthology.org/2024.sighan-1.18/](https://aclanthology.org/2024.sighan-1.18/)
